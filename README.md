# TS-scale-interpretation
In text simplification, several different rating scales are currenlty used. In this code, we propose a method for a sanity check of the human judgments. If a corpu contains sentence pairs, which are identical, the ratings of these pairs can be used to check the scale interpretation of the annotators, e.g., if all raters annotated the simplicity or the meaning preservation with expected values. This analysis can show if different scale interpretation exist. The example code analyses the human judements provided for HSplit, ASSET, Human-likert, System-likert, QATS, Fusion and PWKP-test. The results are published in ["When the Scale is Unclear – Analysis of the Interpretation of Rating Scales in Human Evaluation of Text Simplification" (Stodden, 2021)](http://ceur-ws.org/Vol-2944/paper6.pdf).


## Authors

If you have any question, please contact the author:

**Regina Stodden** (Heinrich-Heine-University, Düsseldorf, Germany) ([regina.stodden@hhu.de](mailto:regina.stodden@hhu.de))

## Citation
If you use our work, please cite:

```bibtex
@inproceedings{stodden-2021-scale-unclear,
    author = {Regina Stodden},
    title = {When the Scale is Unclear – Analysis of the Interpretation of Rating Scales in Human Evaluation of Text Simplification},
    booktitle = {Proceedings of the First Workshop on Current Trends in Text Simplification (CTTS 2021)},
    year = {2021},
    location = {online},
    pages = {84-95},
    organization={CEUR-WS},
    editor = {Horacio Saggion, Sanja Štajner, Daniel Ferrés, Kim Cheng Sheang},
    url = {http://ceur-ws.org/Vol-2944/paper6.pdf},
}
```


## License

See the [LICENSE](LICENSE) file for more details.
